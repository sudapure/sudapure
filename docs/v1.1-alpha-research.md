# Multi Attribute Recognition Release based on DeepM.A.R & Weakly Supervised Implementation

This release contains baseline implementation of DeepM.A.R & Weakly Supervised approaches as covered in PR #41, this release was supposed to be published on 07/07/2021 but due to PR related issues it got delayed, the experimentation's covered in this release signifies to initial level implementation for multi attribute recognition problem.

## Dataset Used
All the experimentation's conducted for this release has been done on [v0.1-alpha](https://github.com/onearmbandit/VAS-Data-Science/releases/tag/v0.1-alpha) dataset release.
<table><td>
<img src="https://user-images.githubusercontent.com/57352045/120796875-f8638e00-c558-11eb-922f-4450a2651737.png"/></td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120797283-732ca900-c559-11eb-8469-bd9e77dbfd1e.png"/></td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120797438-aa9b5580-c559-11eb-8624-71e5871b2fb9.png"/></td>
</table>

**NOTE**: _**The number of data samples showed in above graphs are only from the training datasets. for detailed graphical analysis of complete dataset(train/test/val) has described in the [E.D.A document](https://github.com/onearmbandit/VAS-Data-Science/releases/download/v0.1-alpha/PETA.and.RAP.Dataset.EDA.Report.pdf) respectively**_.
<br/>


## Experimentation Details
As per PR #41 the 3 results mentioned in the [doc](https://github.com/onearmbandit/VAS-Core-Research/files/6616097/PAR_.Results._08_06_21.xlsx) refers to same implementation with 3 different experimentation's conducted by changing the hyper-parameters(lr, weight decay, optimizer) and the loss function , the baseline model architecture is same for all the three experimentation's, from the results attached in the above [docs](https://github.com/onearmbandit/VAS-Core-Research/issues/33#issuecomment-854652311) are the difference in the results for 3 undertaken experimentation's as below,
1. As it can be showed in the following loss/error graph the hyper-parameters for `exp-1` and `exp-3` seems to be the cause for unexpected accuracy numbers, in `exp-1` graph the loss curve doesn't seem to be getting down exponentially rather looks very fluctuating,which looks same with the `exp-3` also, this could be mainly caused due to no co-relation between model hyper-parameters and the loss function, however the loss curve in `exp-2` seems uniform and the loss is also gradually decreasing which shows model has trained well with respect to given loss function over given set of learning parameters.
2. From the below graph it also seems that the models under `exp-1` and `exp-3` are under-fitted , due to the reason mentioned in the above comment, this is the reason why model doesn't produced expected accuracy numbers over test/val dataset.
3. As mentioned in the [release notes](https://github.com/onearmbandit/VAS-Data-Science/releases) of M.A.R dataset and also in this [comment](https://github.com/onearmbandit/VAS-Data-Science/issues/39#issuecomment-842246721) the PETA, RAP dataset contains large amount of common identity images which is shared across train/test/val datasets, due to this reason the results obtained in `exp-2` which seems to be the desired accuracy numbers can possibly called to be an over-fitted accuracy numbers, in another possibility the trained model could also potentially gets over-fitted due to common identity images issue.
<table>
<th>exp-1</th><th>exp-2</th><th>exp-3</th>
<tr><td>
<img src="https://user-images.githubusercontent.com/57352045/120982416-5335f900-c796-11eb-8450-89368b38b42c.jpg"/>
</td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120982445-59c47080-c796-11eb-8a0d-b6e934063332.jpg"/>
</td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120982468-5f21bb00-c796-11eb-9e1f-3ae45570bd34.jpg"/>
</td>
</tr>
</table>

## Conclusive Remark
The `exp-1` and `exp-3` could be reproduced over different hyper-parameters and loss functions, however as mentioned in point 3 the numbers obtained in `exp-2` could mainly caused due to the common identity issue in the existing dataset, however all the experimentation's conducted above were only for the testing purpose, because the large part of the dataset for this problem is still in-progress, in order to get the desired accuracy numbers for this problem real-time dataset needs to be prepared to test it with existing as well as upcoming experimentation results respectively, all the results mentioned in the doc [here](https://github.com/onearmbandit/VAS-Core-Research/files/6598256/Report_withmatrix.docx.pdf) are for testing and experimentation purpose only, the real-time accuracy numbers for this problem needs to be validated independently which will be going to addressed in the upcoming experimentation's and there respective underlying research based implementations.<br/>
<table><td>
<img src="https://user-images.githubusercontent.com/57352045/148671680-ed8772c8-cabb-46c6-9271-17f63ce8caab.png"/></td>
</table>


The infer latency has not been emphasized for this experimentation because the accuracy  numbers are primary emphasize for the above conducted experimentation, however once the expected accuracy numbers obtained will debug and look for infer latency optimization stuff, also computing the F.P.S and latency impact of this with end-to-end detection+tracking scenario is altogether a subject to different experimentation.

## Known Issues

- The code has not been refactored as per preliminary design pattern of S.O.L.I.D convention guidelines (#TODO), refer [discussion](https://github.com/onearmbandit/VAS-Core-Research/discussions/31).
- DVC integration for model versioning is not part of the subsequent commit PR for this release (#TODO), refer [discussion](https://github.com/onearmbandit/VAS-Core-Research/discussions/56)
- Train/Val script has not been refactored as per PyTorch-lighting framework (#TODO), refer [issue](https://github.com/onearmbandit/VAS-Core-Research/issues/48)
- The potential risk of model over-fitting as the constant learning rate is been used throughout, for all training epochs.
- Experimentation standardization needed for all  experimental graph plots & visualization including accuracy metric formulation (#TODO).
- Detailed Profiling & model based Grad-CAM visualization needs to implemented for all experimentation's (#TODO).
- Lack of technical implementation & experimentation specific documentation (#TODO), refer [issue](https://github.com/onearmbandit/VAS-Core-Research/issues/51).

## Evaluation Metrics

<table>
<tr>
<td>Version</td>
<td>Framework/IE</td>
<td>Architecture(GPU/CPU)</td>
<td>Algorithm</td>
<td>Accuracy</td>
<td>latency</td>
<td>FPS</td>
</tr>

<tr>
<td>v1.1-alpha</td>
<td>PyTorch</td>
<td>Nvidia GTX 1050</td>
<td>ResNet-50</td>
<td>91</td>
<td>23 ms</td>
<td>N/A</td>
</tr>


</table>

** All AP(f1 score) numbers are for single-model single-scale, single-channel without ensemble or test-time augmentation. Accuracy here we referring to is based on standard f1-score evaluation metrics, which is based on confusion matrix, precision and recall values. for accuracy validations we are considering confusion matrix parameters with IOU threshold >= 0.5 for detection models only, for classification model IOU is not needed.

** Latency<sub>GPU/CPU</sub> measures end-to-end latency per image/frame averaged over test, validation input sources which can be from RTSP stream or video sources. using specified CPU/GPU architectures, and includes image preprocessing, inference at batch size 1, post-processing and NMS. 

**NOTE**: _The accuracy numbers obtained from above experiment may looks prominent but important thing to note is, the dataset on which the model has trained on has lot of similar appearing image samples which is been described as common identity problem in the release notes of the dataset, so there is high chance that the model got over-fit and potentially may not perform well in real-time scenarios, another reason for model overfiting is stagnant loss which has been overcome by implementing auto learning rate scheduler in the subsequent release_.