# Gender Classification Release based on GenNet architecture for Person UseCase
This release contains baseline implementation of custom GenNet backbone architecture to solve gender classification as binary state problem as covered in PR https://github.com/onearmbandit/VAS-Core-Research/pull/64, this release was supposed to be published on 28/05/2022 but due to PR reviews & other priority tasks it got delayed, the experimentation's covered in this release signifies to preliminary implementation for person gender classification use-case.

## Change Logs
* Implementation of different backbone architectures(GenNet, GenNetv2, RMNet, IBN-Net18-a, etc) by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
* Gender classification experimentation's added to `dvc` by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
*  Implementation of standard inference script for gender-attribute use-case by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
* Transfer learning by loading gender-attribute person weights using ReID as backbone by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
* Implementation of accuracy metric for gender-attribute use-case @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
* Implementation of logger to register accuracy report in text file @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64
* Training experimentation's with different architectures(GenNet, GenNetv2, RMNet, IBN-Net18-a) by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/64

## Issues Resolved
- Preparing & verifying dataset from M.A.R [v0.1-alpha](https://github.com/onearmbandit/VAS-Data-Science/releases/tag/v0.1-alpha) for gender classification use-case as binary classification problem :heavy_check_mark: :1st_place_medal: 
- Implementation of classifier head at top of Re-ID model :heavy_check_mark: :1st_place_medal: 
- Finalizing the hyper-parameters along with loss function & optimizer  :heavy_check_mark: :1st_place_medal: 
- Train the network over given dataset.  :heavy_check_mark: :1st_place_medal: 
- Test/validate the trained model for performance matrices(speed/accuracy).  :heavy_check_mark: :1st_place_medal: 
- Modifying dataloader module as per binary classification use-case  :heavy_check_mark: :1st_place_medal: 
- Implementation of independent accuracy validation script/module.  :heavy_check_mark: :1st_place_medal: 
- Implementation of test infer sample as demo P.O.C.  :heavy_check_mark: :1st_place_medal: 

## Specification
<table>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
<tr>
<td>Pose coverage</td>
<td>Standing upright, parallel to image plane</td>
</tr>
<tr>
<td>Camera Angle</td>
<td><= &ang;40&#176;</td>
</tr>
<tr>
<td>Support of occluded pedestrians </td>
<td>Yes</td>
</tr>
<tr>
<td>Occlusion coverage  </td>
<td> <50% </td>
</tr>
<tr>
<td>GFlops  </td>
<td>N/A </td>
</tr>
<tr>
<td>MParams   </td>
<td>N/A </td>
</tr>
<tr>
<td>Source framework </td>
<td>PyTorch </td>
</tr>
</table>


## Dataset Used
Dataset from PR [278](https://github.com/onearmbandit/VAS-Data-Science/pull/278) & PR [279](https://github.com/onearmbandit/VAS-Data-Science/pull/279) was used for training the model, this dataset is generated from object365 detection dataset for gender and multi-attribute classification use-case, and M.A.R [v0.1-alpha](https://github.com/onearmbandit/VAS-Data-Science/releases/tag/v0.1-alpha) used for test evaluation of the model. dataset in release [v0.1-alpha](https://github.com/onearmbandit/VAS-Data-Science/releases/tag/v0.1-alpha) is a large-scale public benchmark dataset for M.A.R. The dataset contains 33507 images, and this dataset version is created by filtering and rectifying all the images from PETA RAP public dataset

<table><td>
<img src="https://user-images.githubusercontent.com/57352045/120796875-f8638e00-c558-11eb-922f-4450a2651737.png"/></td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120797283-732ca900-c559-11eb-8469-bd9e77dbfd1e.png"/></td>
<td>
<img src="https://user-images.githubusercontent.com/57352045/120797438-aa9b5580-c559-11eb-8624-71e5871b2fb9.png"/></td>
</table>

**NOTE**: _**The number of data samples showed in above graphs are only from the training datasets. for detailed graphical analysis of complete dataset(train/test/val) has described in the [E.D.A document](https://github.com/onearmbandit/VAS-Data-Science/releases/download/v0.1-alpha/PETA.and.RAP.Dataset.EDA.Report.pdf) respectively**. Dataset used is not manually verified., other required dataset is currently in progress as under PR & issue on [onearmbandit/VAS-Data-Science](https://github.com/onearmbandit/VAS-Data-Science)_.

## Experimentation Details
There are different experimentation's conducted on given architectures with all possible combinations for distinct loss functions, optimizer, learning rate, weight decays,etc. however amongst all the architectures GenNet seems to perform well in terms of speed/accuracy trade-off , hence the experimentation details of GenNet is only emphasized in this release, for detailed descriptions of all experimentation's conducted on other architectures refer to [this](https://docs.google.com/document/d/1TXSOeFYG2ayfZt3lmDAFHXKAv5O-SqaalmPMnoTGDOg/edit?usp=sharing) doc.

### Network Architecture
<table><td>
<img src="https://user-images.githubusercontent.com/57352045/172470556-c981cbd9-e22c-4c4e-9b7a-912e2c08c28c.png"/></td>
<td>
<img src="https://user-images.githubusercontent.com/72791642/172629994-98341f7b-55c7-42a1-85ae-8f82670832b5.png" width="200" height="600"/></td>
</table>


```
image_dimension : (3, 256, 128)
optimizer : ([Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)], [{'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f822dd32e50>, 'name': 'learning_rate_monitor', 'monitor': 'validation_loss'}])
max_epochs : 100
min_epochs : 10
loss : BCEWithLogitsLoss()
learning_rate : 0.01
```


### Loss function
This architecture was tested on CELoss and BCELoss function, loss implemented as per Strong-baseline research paper [here](https://github.com/ajithvallabai/Pedestrian_Attribute_Recognition).

#### BCELoss 
This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability

<p align='left'>
<img src="https://user-images.githubusercontent.com/72791642/172637293-80a76f23-2416-45e8-90ef-fef440048044.png"/>
</p>


#### CELoss sigmoid
CELoss introduced in  [Rethinking of Pedestrian Attribute Recognition Realistic Datasets and A Strong Baseline(code)](https://arxiv.org/pdf/2005.11909.pdf) They proposed weighted sigmoid cross entropy loss 
<p align='left'>
<img src="https://user-images.githubusercontent.com/57352045/148695020-598c9c68-5d00-4f88-bd4f-a814243be5f0.png"/>
</p>

Where W</sub>j</sub> is represented as,

![Screenshot from 2022-01-09 23-45-51](https://user-images.githubusercontent.com/57352045/148695025-e298e370-3c28-4d34-9344-aea2b4d1f0a7.png)


## Implementation
Model was initialized with random weights and was trained for 50 epochs using run-time masking, F1 score of 0.89 was achieved on 12th epoch.  All Training logs experiments are stored in DVC. Below are the result are noted with TTA(Test TIme Augmentation).
<p align='center'>
<img src="https://user-images.githubusercontent.com/72791642/172636511-c0544e7f-98b2-4189-856f-bb5fe7133268.png"/>
</p>


Above mentioned evaluation metric is the best achieved readings as per the combination of hyper-parameters, optimizer & loss function experimented & documented in the [doc](https://docs.google.com/document/d/1TXSOeFYG2ayfZt3lmDAFHXKAv5O-SqaalmPMnoTGDOg/edit?usp=sharing), however apart from above results following are results observed as a combination of experimenting with different architectures, optimizer & loss function,

<p align='center'>
<video src="https://user-images.githubusercontent.com/57352045/172467972-60279b33-69ba-4b74-a146-bbc56b7c85b1.mp4">
</video>
</p>


## Conclusive Remark
**As per observations model performs well on training and validation dataset but doesn't perform well when tested on real time dataset**. This is because the differentiating factor in between inter-class variation for supervised solution needs to be extremely descriptive , as addressing this approach based on complete R.O.I of person body which inevitably includes some part of background as well contains very limited feature information with discriminating latent space representation, this is essentially because Man & Women wears mostly similar type of cloths including other accessorial attributes, which makes it tricky for any classification algorithm to differentiate between the two, however the problem can be more accurately addressed using facial attribute recognition problem instead of having compete human body as input R.O.I.
Another factor is finite number of data samples to train full body gender classification, As this task has low inter-class variation the model tends to over-fit on the dataset which affects generalization ability of the model, for instance if the person is wearing a sleeveless T-shirt, model classifies the person into female to address this data drift, a massive amount of data samples needs to be collected.

## Known Issues
- As mentioned above model performs well on training and validation dataset but when tested on real time dataset accuracy of the model drops significantly 
- Lack of discriminative inter-class features makes gender classification difficult 
- Limited number of data samples 

## Further improvements (#TODO):
- Utilizing more amount of discrete dataset, to further improve model accuracy and minimizing the risk of over-fitting.
- Modifying the model architecture to learn more in depth features to minimize false classifications.
- NN architecture optimization & decreasing trainable parameter to further improve latency numbers
- Use-case specific architecture need to be implemented to achieve best speed/accuracy trade-off.
- Fine-tuning gender classification use-case on top of unsupervised learning approach as per PR #71 
- Experimentation with different training strategies as mentioned in issue #72 
- Addressing the gender classification using facial attribute problem instead of full body R.O.I as input.


## Evaluation Metrics

<table>
<tr>
<td>Version</td>
<td>Use-Case</td>
<td>Framework/IE</td>
<td>Architecture(GPU/CPU)</td>
<td>Algorithm</td>
<td>Accuracy (f1-score)</td>
<td>Precision</td>
<td>latency</td>
<td>FPS</td>
</tr>

<tr>
<td>v1.5-beta</td>
<td>Gender Classification</td>
<td>PyTorch</td>
<td>Nvidia GTX 1060</td>
<td>GenNet</td>
<td>78</td>
<td>FP32</td>
<td>0.82 ms</td>
<td>N/A</td>
</tr>

</table>

** All AP(f1 score) numbers are for single-model single-scale, single-channel without ensemble or test-time augmentation. Accuracy here we referring to is based on standard f1-score evaluation metrics with TTA, which is based on confusion matrix, precision and recall values. for accuracy validations we are considering confusion matrix parameters with IOU threshold >= 0.5 for detection models only, for classification model IOU is not needed.

** Latency<sub>GPU/CPU</sub> measures end-to-end latency per image/frame averaged over test, validation input sources which can be from RTSP stream or video sources. using specified CPU/GPU architectures, and includes image preprocessing, inference at batch size 1, post-processing and NMS. 

**NOTE**: _The accuracy numbers obtained from above experiment may looks prominent but important thing to note is, the dataset on which the model has trained on has lot of similar appearing image samples which is been described as common identity problem in the release notes of the dataset, so there is high chance that the model got over-fit and potentially may not perform well in real-time scenarios, another reason for model overfiting is stagnant loss which has been overcome by implementing auto learning rate scheduler in the subsequent release_.

