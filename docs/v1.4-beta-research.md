# Person Re-ID Release based on Resnet-IBN-Net-18-a architecture for Person UseCase
This release contains baseline implementation of IBN-Net(ResNet-18/ResNet-18-a/ResNet-50) backbone architecture to solve person Re-ID problem as covered in PR https://github.com/onearmbandit/VAS-Core-Research/pull/54, this release was supposed to be published on 01/3/2022 but due to PR reviews & other priority tasks it got delayed, the experimentation's covered in this release signifies to preliminary implementation for person Re-ID problem.

## Change Logs
* centroid reid experimentation added to `dvc` by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/54
* added Image retrieval in image_retrieval.py  by @sarveshamberkarC @sudapure  in https://github.com/onearmbandit/VAS-Core-Research/pull/54
*  Implementation of standard inference script for multi-attribute use-case by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/57
* Transfer learning by loading multi-attribute person weights in ReID by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/57
* Implementation of accuracy metric for multi-attribute use-case @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/57
* Implementation of logger to register accuracy report in text file @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/57
* implementation loader package to support multiple input type for accuracy metrics like csv, torch.tensor etc @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/57
* IBN-Net Re-ID   by @sarveshamberkarC in https://github.com/onearmbandit/VAS-Core-Research/pull/54

## Issues Resolved
- Training backbone network(ResNet,VGG,Custom) from scratch for person classification problem #38 :heavy_check_mark: :1st_place_medal: 
- implementation and experimentation of triplet loss with IBN-Net architecture, refer to [base paper](https://arxiv.org/pdf/1503.03832.pdf)  :heavy_check_mark: :1st_place_medal: 
- Implementation and experimentation of circle loss with IBN-Net architecture, refer to [base paper](https://arxiv.org/pdf/2002.10857.pdf)  :heavy_check_mark: :1st_place_medal: 
- Customizing/refactoring the dataloader module as per triplet anchors for PyTorch-lighhting based implementation  :heavy_check_mark: :1st_place_medal: 
- Customizing the output layer of NN architecture to train & validate over triplet, circle loss.  :heavy_check_mark: :1st_place_medal: 
- Training & validating the modified NN.  :heavy_check_mark: :1st_place_medal: 
- Reproducing and experimenting triplet, circle loss implementation and documenting the same as per issue 
https://github.com/onearmbandit/VAS-Core-Research/issues/51.  :heavy_check_mark: :1st_place_medal: 
- Implementing or re-using the image content retrieval/re-ranking script for infer testing.  :heavy_check_mark: :1st_place_medal: 
- Implementing and validating the accuracy as per Re-Id benchmark using separate infer script.  :heavy_check_mark: :1st_place_medal: 
- cross validation of accuracy metric of centroid-reid with https://github.com/onearmbandit/VAS-Data-Science/pull/175  :heavy_check_mark: :1st_place_medal: 
- Tensorboard Projector implementation for Centroid-ReID.  :heavy_check_mark: :1st_place_medal: 


## Specification
<table>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
<tr>
<td>Market-1501 rank@1 accuracy</td>
<td>84</td>
</tr>
<tr>
<td>Market-1501 mAP</td>
<td>0.67</td>
</tr>
<tr>
<td>Pose coverage</td>
<td>Standing upright, parallel to image plane</td>
</tr>
<tr>
<td>Camera Angle</td>
<td><= &ang;40&#176;</td>
</tr>
<tr>
<td>Support of occluded pedestrians </td>
<td>Yes</td>
</tr>
<tr>
<td>Occlusion coverage  </td>
<td> <50% </td>
</tr>
<tr>
<td>GFlops  </td>
<td>N/A </td>
</tr>
<tr>
<td>MParams   </td>
<td>N/A </td>
</tr>
<tr>
<td>Source framework </td>
<td>PyTorch </td>
</tr>
</table>

## Dataset Used
Market1501 Dataset was used for training and evaluation of the model. Market-1501 is a large-scale public benchmark dataset for person re-identification. It contains 1501 identities which are captured by six different cameras, and 32,668 pedestrian image bounding-boxes obtained using the Deformable Part Models pedestrian detector. Each person has 3.6 images on average at each viewpoint. The dataset is split into two parts: 750 identities are utilized for training and the remaining 751 identities are used for testing. In the official testing protocol 3,368 query images are selected as a probe set to find the correct match across 19,732 reference gallery images.

**Note**: _Dataset used is not manually verified., other required dataset is currently in progress as under PR & issue on [onearmbandit/VAS-Data-Science](https://github.com/onearmbandit/VAS-Data-Science)_

## Experimentation Details
There are different experimentation's conducted on given architectures with all possible combinations for distinct loss functions, optimizer, learning rate, weight decays,etc. however amongst all the architectures IBN-Net ResNet-18-a seems to perform well in terms of speed/accuracy trade-off , hence the experimentation details of IBN-Net is only emphasized in this release, for detailed descriptions of all experimentation's conducted on other architectures refer to [this](https://docs.google.com/document/d/1OMxwlCedrsxOHhfWJDdXBUI44zozGDlpwGGIOMNAa_A/edit#heading=h.rwubogtek0go) doc.
**IBN-Net**, is a novel convolutional architecture, which remarkably enhances a CNN?s modeling ability on one domain (e.g. Cityscapes) as well as its generalization capacity on another domain (e.g. GTA5) without fine-tuning. IBN-Net carefully integrates Instance Normalization (IN) and Batch Normalization (BN) as building blocks, and can be wrapped into many advanced deep networks to improve their performances, as per the experimentation's conducted down the line IBN has been incorporated with ResNet-18 architecture, it can also be integrated with other S.O.T.A architectures like OS-Net, Efficient-Net, Res-Next, or even use-case specific custom CNN's.

### Network Architecture
<p align='center'>
<img src="https://user-images.githubusercontent.com/57352045/148694823-025b41dc-4759-447a-8d4b-87c89ea3a164.png"/>
</p>

### Loss function
The architecture was trained using weighted summation of three loss functions.Which are listed as follows
**Cross entropy loss with label smoothing regularizer**
Cross-entropy loss is the sum of the negative logarithm of predicted probabilities of each class
<p align='center'>
<img src="https://user-images.githubusercontent.com/57352045/157855887-4a0fe152-138d-4848-8607-073020d92aac.png"/>
</p>

Label smoothing: Label smoothing is a regularization technique that addresses Two problems which is overfitting, and overconfidence.

**Triplet Loss**:
Triplet loss used in this implementation is modified triplet loss mentioned in In paper Defense of the Triplet Loss for Person Re-Identification. Original implementation of the loss function can be found [here](https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py).

**_Triplet loss function is applied twice in the training step for centroid and for triplet images separately_**.

**Center loss** :
the center loss simultaneously learns a center for deep features of each class and penalizes the distances between the deep features and their corresponding class centers This idea was originally proposed in A Discriminative Feature Learning Approach for Deep Face Recognition

## Implementation
Model was trained from random weight initialization for 120 epoch and a `mAP` score of 0.6767 was achieved on 119th epoch. All Training logs experiments stored in DVC. Below results are taken with TTA(Test Time Augmentation) however it is observed that without TTA accuracy drops drastically,
<p align='center'>
<img src="https://user-images.githubusercontent.com/57352045/157899672-2fd4ecde-b248-4b85-8cf5-c06abe8093fa.png"/>
</p>
Above mentioned evaluation metric is the best achieved readings as per the combination of hyper-parameters, optimizer & loss function experimented & documented in the doc, however apart from above results following are results observed as a combination of experimenting with different architectures, optimizer & loss function,

<p align='center'>
<table>
<th>Architecture</th>
<th>Loss Function</th>
<th>Optimizer</th>
<th>mAP</th>
<th>top-k, Rank-1</th>


<tr>
<td>IBN-Net(ResNet-50)</td>
<td>Cross entropy + Center loss + Triplet loss</td>
<td>Adam</td>
<td>0.6948</td>
<td>86.0%</td>
</tr>

<tr>
<td><strong>IBN-Net(ResNet-18-a)</strong></td>
<td><strong>Cross entropy + Center loss + Triplet loss</strong></td>
<td><strong>Adam</strong></td>
<td><strong>0.65199</strong></td>
<td><strong>84.9%</strong></td>
</tr>
<tr>
<td>IBN-Net(ResNet-18-a)</td>
<td>Cross Entropy + Hard Triplet loss</td>
<td>Adam</td>
<td>0.2</td>
<td>0.1%</td>
</tr>

<tr>
<td>IBN-Net(ResNet-18-a)</td>
<td>Cross entropy + Semi-hard Triplet + Hard Triplet loss</td>
<td>Adam</td>
<td>12.1</td>
<td>28.1%</td>
</tr>

<tr>
<td>IBN-Net(ResNet-18-a)</td>
<td>Cross entropy + Circle loss</td>
<td>Adam</td>
<td>0.3</td>
<td>0.1%</td>
</tr>

</table>
</p>

### Design Architecture
Below diagram shows different components and it's respective dimensions used in training phase and corresponding output nodes that are used for training and inferencing, here the ReID head will change in dimensions for Person & Vehicle use-case, however the backbone network will remain same for both the use-cases.
<p align='center'>
<img src="https://user-images.githubusercontent.com/57352045/157907477-5eeb8e5e-5bcd-46b6-872e-3a195aa6ee98.png"/>
</p>

### 3D Modeling Projection
Below is sample video of visualization of model output and forming 3D clusters by grouping of similar appearing PID's(Person images), to visualize below result tensorborad projector implementation has been used with t-SNE algorithm for dimensionality reduction by keeping the feature information intact, as from below video it can be seen that the clusters are forming very unique & distinct group representations with minimal anomaly for all identical appearing PID's which shows that the trained model is effectively working for the given use-case.

https://user-images.githubusercontent.com/72791642/157427622-fca13fe2-3b2c-4b7a-a996-734cd649f339.mp4

### Application Utility
For quick evaluation  of trained Re-ID model the feature embedding are used with image retrieval problem to retrieve relevant appearing images from the set of gallery images, below are two scenarios where in first one the query image & retrieved results are close enough as in the second case the input & retrieved images are pretty distinct indicating as worst case scenario.
<table>
<th colspan="2" align='center'>
Best Case
</th>
<tr align='center'>
<td>Input Query</td>
<td>Top-k Results</td>
</tr>

<tr>
<td><img src="https://user-images.githubusercontent.com/57352045/158007533-4895d3f7-2451-4b50-9678-e85fa0c7bc6c.png"/></td>
<td><img src="https://user-images.githubusercontent.com/57352045/158007531-8292a70e-f732-42d0-8e9d-ce40413e4458.png"/></td>
</tr>

<th colspan="2" align='center'>
Worst Case
</th>
<tr align='center'>
<td>Input Query</td>
<td>Top-k Results</td>
</tr>

<tr>
<td><img src="https://user-images.githubusercontent.com/57352045/158019941-26ace696-dd50-4bb4-888c-d6cc1d799c02.png"/></td>
<td><img src="https://user-images.githubusercontent.com/57352045/158019938-0a93d7d9-92df-49e7-be6a-3fa035ce938e.png"/></td>
</tr>
</table>

## Conclusive Remark
All the experimentation's conducted in PR #54 were only for the training & validation purpose, because the large part of the dataset for this problem is still in-progress, in order to get the desired accuracy numbers for this problem real-time dataset needs to be prepared to test it with existing as well as upcoming experimentation results respectively, all the results mentioned in the doc [here](https://docs.google.com/document/d/1OMxwlCedrsxOHhfWJDdXBUI44zozGDlpwGGIOMNAa_A/edit) are for testing and experimentation purpose only, the real-time accuracy numbers for this problem needs to be validated independently which will be going to addressed in the upcoming experimentation's and there respective underlying research based implementations. The infer latency has not been emphasized for this experimentation because the accuracy numbers are primary emphasize for the above conducted experiments, the NN design specific optimizations in order to optimze latency numbers are going to be addressed in upcoming release for Re-ID, also computing the F.P.S and latency impact of this with end-to-end detection+tracking scenario is altogether a subject to different experimentation.

## known Issues
- The code has not been refactored as per preliminary design pattern of S.O.L.I.D convention guidelines (#TODO), refer https://github.com/onearmbandit/VAS-Core-Research/discussions/31.
- Without TTA accuracy drops drastically, this is very critical issue as in deployment release TTA is not required.
- The potential risk of model over-fitting because of the common identity issue in the dataset.
- Experimentation standardization needed for all experimental graph plots & visualization (#TODO).
- Model is not optimized with respect to latency parameter.
- Model is not trained with Reviewed Dataset, also single source dataset is used for training & validation.

## Further improvements (#TODO):
- Detailed Profiling & model based Grad-CAM visualization need to be implemented for further experimentation's (#TODO).
- Improving accuracy without TTA, which is crucial for deployment specific releases.
- NN architecture optimization & decreasing trainable parameter to further improve latency numbers
- Multi-source balanced dataset required to achieve more reliable accuracy numbers.
- Use-case specific architecture need to be implemented to achieve best speed/accuracy trade-off.

## Evaluation Metrics
<table>
<tr>
<td>Version</td>
<td>Use-Case</td>
<td>Framework/IE</td>
<td>Architecture(GPU/CPU)</td>
<td>Algorithm</td>
<td>Accuracy</td>
<td>latency</td>
<td>FPS</td>
</tr>

<tr>
<td>v1.4-beta</td>
<td>Person Re-ID</td>
<td>PyTorch</td>
<td>Nvidia GTX 1060</td>
<td>IBN-Net-ResNet-18-a</td>
<td>0.65 mAP</td>
<td>2.73 ms</td>
<td>N/A</td>
</tr>
<tr>
<td>v1.4-beta</td>
<td>Person Retrieval</td>
<td>PyTorch</td>
<td>Nvidia GTX 1060</td>
<td>IBN-Net-ResNet-18-a</td>
<td>84% @ Rank-1</td>
<td>2.73 ms</td>
<td>N/A</td>
</tr>

</table>

** All Accuracy numbers are for single-model single-scale, single-channel without ensemble or test-time augmentation. Accuracy here we referring to is based on standard CMC `mAP` and ranking based evaluation metrics with TTA, however the `mAP` used in this case is different from the `mAP` parameter used in detection or segmentation use-case.

** Latency<sub>GPU/CPU</sub> measures mentioned in the experiments are considered with respect to backbone model inference, the end-to-end latency numbers for image retrieval has not been considered as it is altogether a subject to different experimentation and use-case specific requirement.. 

**NOTE**: _The accuracy numbers obtained from above experiment may looks prominent but important thing to note is, the dataset on which the model has trained on has lot of similar appearing image samples which is been described as common identity problem in the release notes of the dataset, so there is high chance that the model got over-fit and potentially may not perform well in real-time scenarios_.
